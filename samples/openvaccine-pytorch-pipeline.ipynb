{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing models.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile models.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SpatialDropout(nn.Dropout2d):\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)  \n",
    "        x = super(SpatialDropout, self).forward(x)  \n",
    "        x = x.permute(0, 2, 1)  \n",
    "        return x\n",
    "    \n",
    "\n",
    "class GRU_model(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        args,\n",
    "        pred_len=68\n",
    "    ):\n",
    "        super(GRU_model, self).__init__()\n",
    "        self.pred_len = pred_len\n",
    "\n",
    "        self.embedding = nn.Embedding(num_embeddings=args.num_embeddings, embedding_dim=args.embedding_dim)\n",
    "        self.cnn_layer = nn.Conv1d(in_channels=16, out_channels=args.embedding_dim, kernel_size=5, padding=5//2)\n",
    "        \n",
    "        self.embedding_dropout = SpatialDropout(0.3)\n",
    "\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=args.embedding_dim,\n",
    "            hidden_size=args.hidden_size,\n",
    "            num_layers=args.hidden_layers,\n",
    "            dropout=args.dropout,\n",
    "            bidirectional=True,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.linear = nn.Linear(args.hidden_size * 2, 5)\n",
    "\n",
    "    def forward(self, seqs):\n",
    "        seqs = seqs.permute(0, 2, 1)\n",
    "        embed = self.cnn_layer(seqs)\n",
    "        embed = self.embedding_dropout(embed)\n",
    "        reshaped = embed.permute(0, 2, 1) #torch.reshape(embed, (-1, embed.shape[1], embed.shape[2] * embed.shape[3]))\n",
    "        output, hidden = self.gru(reshaped)\n",
    "        turncated = output[:, :self.pred_len, :]\n",
    "        out = self.linear(turncated)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing dataset.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile dataset.py\n",
    "\n",
    "import numpy as np, pandas as pd\n",
    "import torch, torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "target_col = ['reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C', 'deg_50C']\n",
    "\n",
    "rna_dict    = {x:i for i, x in enumerate('ACGU')} #4\n",
    "struct_dict = {x:i for i, x in enumerate('().')}  #3\n",
    "loop_dict   = {x:i for i, x in enumerate('BEHIMSX')}#7\n",
    "\n",
    "class RNADataset(Dataset):\n",
    "    def __init__(self, df, augment=None):\n",
    "\n",
    "        self.rna    = df['sequence'].map(lambda seq: [rna_dict[x] for x in seq])\n",
    "        self.struct = df['structure'].map(lambda seq: [struct_dict[x] for x in seq])\n",
    "        self.loop   = df['predicted_loop_type'].map(lambda seq: [loop_dict[x] for x in seq])\n",
    "\n",
    "        bbp0 =[]\n",
    "        bbp1 =[]\n",
    "        id = df.id.values\n",
    "        for i in id:\n",
    "            probability = np.load(f'../bpps/{i}.npy')\n",
    "            bbp0.append(probability.max(-1).tolist())\n",
    "            bbp1.append((1-probability.sum(-1)).tolist())\n",
    "        self.bbp0 = bbp0\n",
    "        self.bbp1 = bbp1\n",
    "\n",
    "        #---\n",
    "        if 'reactivity' in df.columns:\n",
    "            target = np.transpose(\n",
    "                df[target_col]\n",
    "                .values\n",
    "                .tolist(),\n",
    "            (0, 2, 1))\n",
    "            target = np.ascontiguousarray(target)\n",
    "        else:\n",
    "            target = np.zeros((len(df),1,1)) #dummy\n",
    "\n",
    "        self.df =  df\n",
    "        self.len = len(self.df)\n",
    "        self.augment = augment\n",
    "        self.target = target\n",
    "\n",
    "    def __str__(self):\n",
    "        string  = ''\n",
    "        string += '\\tlen  = %d\\n'%len(self)\n",
    "        return string\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        r = self.df.loc[index]\n",
    "        target = self.target[index]\n",
    "\n",
    "        rna = np.array(self.rna[index])\n",
    "        struct = np.array(self.struct[index])\n",
    "        loop = np.array(self.loop[index])\n",
    "        bbp0 = np.array(self.bbp0[index]).reshape(-1,1)\n",
    "        bbp1 = np.array(self.bbp1[index]).reshape(-1,1)\n",
    "\n",
    "        #bbp = np.load(f'../input/stanford-covid-vaccine/bpps/{r.id}.npy')\n",
    "        #bbp = np.expand_dims(bbp, axis=0)\n",
    "\n",
    "        seq = np.concatenate([\n",
    "            np_onehot(rna,4),\n",
    "            np_onehot(struct,3),\n",
    "            np_onehot(loop,7),\n",
    "            bbp0,\n",
    "            bbp1,\n",
    "        ],1)\n",
    "\n",
    "        #------\n",
    "        record = {\n",
    "            'target': torch.tensor(target, dtype=torch.float),\n",
    "            #'bbps'  : torch.tensor(bbp, dtype=torch.float),\n",
    "            'seq' : torch.tensor(seq, dtype=torch.float),\n",
    "            'ids' : r.id\n",
    "        }\n",
    "        if self.augment is not None: record = self.augment(record)\n",
    "        return record\n",
    "\n",
    "def np_onehot(x, max=54):\n",
    "    return np.eye(max)[x]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing losses.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile losses.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MCRMSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "    \n",
    "    def rmse(self, y_actual, y_pred):\n",
    "        mse = self.mse(y_actual, y_pred)\n",
    "        return torch.sqrt(mse)\n",
    "    \n",
    "    def forward(self, y_actual, y_pred, num_scored=None):\n",
    "        if num_scored == None:\n",
    "            num_scored = y_actual.shape[-1]\n",
    "        score = 0\n",
    "        for i in range(num_scored):\n",
    "            score += self.rmse(y_actual[:, :, i], y_pred[:, :, i]) / num_scored\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing utils.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile utils.py\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train.py\n",
    "\n",
    "import math, json, gc, random, os, sys, time\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from tqdm import tqdm\n",
    "\n",
    "import models\n",
    "import losses\n",
    "from dataset import RNADataset\n",
    "from utils import AverageMeter\n",
    "from config import args\n",
    "\n",
    "## Model\n",
    "#get comp data\n",
    "train = pd.read_json('../train.json', lines=True)\n",
    "test = pd.read_json('../test.json', lines=True)\n",
    "sample_sub = pd.read_csv(\"../sample_submission.csv\")\n",
    "\n",
    "target_cols = ['reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C', 'deg_50C']\n",
    "\n",
    "train = train[train.signal_to_noise >= 1]\n",
    "\n",
    "\n",
    "def train_epcoh(model, loader, optimizer, criterion, device, epoch):\n",
    "    losses = AverageMeter()\n",
    "\n",
    "    model.train()\n",
    "    t = tqdm(loader)\n",
    "    for i, d in enumerate(t):\n",
    "\n",
    "        #print(d)\n",
    "\n",
    "        X = d['seq'].to(device)\n",
    "        y = d['target'].to(device)\n",
    "\n",
    "        pred_y = model(X)\n",
    "\n",
    "        loss = criterion(y, pred_y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        bs = X.size(0)\n",
    "        losses.update(loss.item(), bs)\n",
    "\n",
    "        t.set_description(f\"Train E:{epoch} - Loss:{losses.avg:0.5f}\")\n",
    "    \n",
    "    t.close()\n",
    "    return losses.avg\n",
    "\n",
    "def valid_epoch(model, loader, criterion, device, epoch):\n",
    "    losses = AverageMeter()\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        t = tqdm(loader)\n",
    "        for i, d in enumerate(t):\n",
    "\n",
    "            X = d['seq'].to(device)\n",
    "            y = d['target'].to(device)\n",
    "\n",
    "            pred_y = model(X)\n",
    "            \n",
    "            #print(y.shape, pred_y.shape)\n",
    "            \n",
    "            loss = criterion(y, pred_y)\n",
    "\n",
    "            bs = X.size(0)\n",
    "            losses.update(loss.item(), bs)\n",
    "\n",
    "            t.set_description(f\"Valid E:{epoch} - Loss:{losses.avg:0.5f}\")\n",
    "        \n",
    "    t.close()\n",
    "    return losses.avg\n",
    "\n",
    "def test_predic(model, loader, device):\n",
    "    \n",
    "    outputs_dict = {\n",
    "        \"ids\" : [],\n",
    "        \"predicts\" : []\n",
    "    }\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        t = tqdm(loader)\n",
    "        for i, d in enumerate(t):\n",
    "            X = d['seq'].float().to(device)\n",
    "            ids = d['ids']\n",
    "            \n",
    "            outs = model(X).cpu().detach().numpy().tolist()\n",
    "            \n",
    "            outputs_dict['predicts'].extend(outs)\n",
    "            outputs_dict['ids'].extend(ids)\n",
    "            \n",
    "    return outputs_dict\n",
    "\n",
    "def main():\n",
    "\n",
    "    # Setting seed\n",
    "    seed = args.seed\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    \n",
    "    args.save_path = os.path.join(args.output_dir, args.exp_name)\n",
    "    os.makedirs(args.save_path, exist_ok=True)\n",
    "\n",
    "    public_predictions = [] \n",
    "    public_ids         = []\n",
    "\n",
    "    private_predictions = []\n",
    "    private_ids         = []\n",
    "\n",
    "    public_df = test.query(\"seq_length == 107\").reset_index(drop=True)\n",
    "    private_df = test.query(\"seq_length == 130\").reset_index(drop=True)\n",
    "\n",
    "    public_dataset = RNADataset(public_df)\n",
    "    private_dataset = RNADataset(private_df)\n",
    "\n",
    "    public_loader = DataLoader(public_dataset, batch_size=args.batch_size, shuffle=False)\n",
    "    private_loader = DataLoader(private_dataset, batch_size=args.batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    skf = KFold(args.n_folds, shuffle=True, random_state=seed)\n",
    "\n",
    "    for i, (train_index, valid_index) in enumerate(skf.split(train, train['SN_filter'])):\n",
    "        print(\"#\"*20)\n",
    "        print(f\"##### Fold : {i}\")\n",
    "\n",
    "        args.fold = i\n",
    "\n",
    "        train_df = train.iloc[train_index].reset_index(drop=True)\n",
    "        valid_df = train.iloc[valid_index].reset_index(drop=True)\n",
    "        \n",
    "        #valid_df = valid_df[valid_df.SN_filter == 1].reset_index(drop=True)\n",
    "\n",
    "        train_dataset = RNADataset(train_df)\n",
    "        valid_dataset = RNADataset(valid_df)\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True)\n",
    "        valid_loader = DataLoader(valid_dataset, batch_size=args.batch_size, shuffle=False)\n",
    "\n",
    "        model = models.__dict__[args.network](args, pred_len=68)\n",
    "        model = model.to(device)\n",
    "\n",
    "        criterion = losses.__dict__[args.losses]()\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "\n",
    "        best_loss = 99999\n",
    "\n",
    "        for epoch in range(args.epochs):\n",
    "\n",
    "            train_loss = train_epcoh(model, train_loader, optimizer, criterion, device, epoch)\n",
    "            valid_loss = valid_epoch(model, valid_loader, criterion, device, epoch)\n",
    "\n",
    "            content = f\"\"\"\n",
    "                {time.ctime()} \\n\n",
    "                Fold:{args.fold}, Epoch:{epoch}, lr:{optimizer.param_groups[0]['lr']:.7}, \\n\n",
    "                Train Loss:{train_loss:0.4f} - Valid Loss:{valid_loss:0.4f} \\n\n",
    "            \"\"\"\n",
    "            print(content)\n",
    "\n",
    "            with open(f'{args.save_path}/log_{args.exp_name}.txt', 'a') as appender:\n",
    "                appender.write(content + '\\n')\n",
    "            \n",
    "            if valid_loss < best_loss:\n",
    "                print(f\"######### >>>>>>> Model Improved from {best_loss} -----> {valid_loss}\")\n",
    "                torch.save(model.state_dict(), os.path.join(args.save_path, f\"fold-{args.fold}.bin\"))\n",
    "                best_loss = valid_loss\n",
    "            \n",
    "            torch.save(model.state_dict(), os.path.join(args.save_path, f\"last-fold-{args.fold}.bin\"))\n",
    "            \n",
    "        public_model = models.__dict__[args.network](args, pred_len=107).to(device)\n",
    "        public_model.load_state_dict(torch.load(os.path.join(args.save_path, f\"fold-{args.fold}.bin\")))\n",
    "        \n",
    "        private_model = models.__dict__[args.network](args, pred_len=130).to(device)\n",
    "        private_model.load_state_dict(torch.load(os.path.join(args.save_path, f\"fold-{args.fold}.bin\")))\n",
    "        \n",
    "        public_pred_dict = test_predic(public_model, public_loader, device)\n",
    "        private_pred_dict = test_predic(private_model, private_loader, device)\n",
    "        \n",
    "        public_predictions.append(np.array(public_pred_dict[\"predicts\"]).reshape(629 * 107 , 5))\n",
    "        private_predictions.append(np.array(private_pred_dict[\"predicts\"]).reshape(3005 * 130, 5))\n",
    "        \n",
    "        public_ids.append(public_pred_dict[\"ids\"])\n",
    "        private_ids.append(private_pred_dict[\"ids\"])\n",
    "\n",
    "    public_ids1 = [f\"{id}_{i}\" for id in public_ids[0] for i in range(107)]\n",
    "    private_ids1 = [f\"{id}_{i}\" for id in private_ids[0] for i in range(130)]\n",
    "\n",
    "    public_preds = np.mean(public_predictions, axis=0)\n",
    "    private_preds = np.mean(private_predictions, axis=0)\n",
    "\n",
    "    public_pred_df = pd.DataFrame(public_preds, columns=target_cols)\n",
    "    public_pred_df[\"id_seqpos\"] = public_ids1\n",
    "\n",
    "    private_pred_df = pd.DataFrame(private_preds, columns=target_cols)\n",
    "    private_pred_df[\"id_seqpos\"] = private_ids1\n",
    "\n",
    "    pred_sub_df = public_pred_df.append(private_pred_df)\n",
    "\n",
    "    pred_sub_df.to_csv(os.path.join(args.save_path, f\"{args.sub_name}_submission.csv\"), index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing config.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile config.py\n",
    "\n",
    "\n",
    "class args:\n",
    "    \n",
    "    exp_name = \"base_model\"\n",
    "    sub_name = \"\"\n",
    "    output_dir = \"weights\"\n",
    "\n",
    "    network = \"GRU_model\"\n",
    "\n",
    "    losses  = \"MCRMSELoss\"\n",
    "\n",
    "    \n",
    "    # Model parameters\n",
    "    num_embeddings = 14\n",
    "    embedding_dim  = 128\n",
    "    hidden_layers  = 3\n",
    "    hidden_size    = 128\n",
    "    dropout        = 0.5\n",
    "\n",
    "    # Training parameters\n",
    "    lr = 0.0001\n",
    "    seed = 42\n",
    "    epochs = 50\n",
    "    n_folds = 5\n",
    "    batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "!py train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
